{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib\n",
    "from subprocess import check_output\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idpath='/home/csv_files/Desktop/123/I.txt'\n",
    "lblpath='/home/csv_files/Desktop/123/l.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=[]\n",
    "with open(idpath) as f:\n",
    "    id=f.read().split('\\n')\n",
    "lbl_id=[]\n",
    "with open(lblpath) as f:\n",
    "    lbl_id=f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath='/home/csv_files/Desktop/123/dataset150'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflz=os.listdir(dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullid=[]\n",
    "for i in dflz:\n",
    "    fullid.append(os.path.join(dpath,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shakeel/Desktop/123/dataset150/58_right.jpg\n",
      "(500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "X=fullid\n",
    "Y=idlbl\n",
    "for i in X:\n",
    "    print(i)\n",
    "    x=cv2.imread(i)\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=140\n",
    "def gen():\n",
    "    for i in range(0,1000,batch_size):\n",
    "        yield X[i:i+batch_size], Y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import newaxis \n",
    "def converttoarray(x,y):\n",
    "    feat,lbl=np.empty((0,500,500,3)),np.empty(0)\n",
    "    for i,j in zip(x,y):\n",
    "        img=cv2.imread(i)\n",
    "        img=img[newaxis,:,:,:]\n",
    "        feat=np.vstack([feat,img])\n",
    "        lbl=np.append(lbl,j)\n",
    "    return feat,lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol=iter(gen())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=next(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "x,y=converttoarray(a,b)\n",
    "onehot=pd.get_dummies(b)\n",
    "target_labels= onehot.columns\n",
    "y= onehot.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('/home/struggler/npies/D1.npy',x)\n",
    "np.savez('/home/struggler/npies/L1.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 500, 500, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 123, 123, 96)      34944     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 123, 123, 96)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 61, 61, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 51, 51, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 51, 51, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 25, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 23, 23, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 23, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 21, 21, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 21, 21, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 21, 21, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 19, 19, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 19, 19, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              84938752  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 5005      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 111,970,837\n",
      "Trainable params: 111,949,701\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (3) Create a sequential model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "np.random.seed(1000)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(500,500,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "105/105 [==============================] - 25s 234ms/step - loss: 0.7606 - acc: 0.7524\n",
      "Epoch 2/5\n",
      "105/105 [==============================] - 25s 237ms/step - loss: 0.8214 - acc: 0.7429\n",
      "Epoch 3/5\n",
      "105/105 [==============================] - 25s 234ms/step - loss: 0.6846 - acc: 0.7714\n",
      "Epoch 4/5\n",
      "105/105 [==============================] - 25s 234ms/step - loss: 0.5987 - acc: 0.8095\n",
      "Epoch 5/5\n",
      "105/105 [==============================] - 25s 236ms/step - loss: 0.6804 - acc: 0.7714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60a47b8588>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "#The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 62ms/step\n",
      "Baseline Error: 17.14%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
